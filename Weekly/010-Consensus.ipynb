{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### portmy database: profits, stocks tables\n",
    "### portpg database: consensus, tickers tables\n",
    "### csv files: consensus-ORD.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 12, 18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "engine = create_engine(\"sqlite:///c:\\\\ruby\\\\portmy\\\\db\\\\development.sqlite3\")\n",
    "conmy = engine.connect()\n",
    "engine = create_engine(\"postgresql+psycopg2://postgres:admin@localhost:5432/portpg_development\")\n",
    "conpg = engine.connect()\n",
    "engine = create_engine(\"sqlite:///c:\\\\ruby\\\\port_lite\\\\db\\\\development.sqlite3\")\n",
    "conlite = engine.connect()\n",
    "engine = create_engine('mysql+pymysql://root:@localhost:3306/stock')\n",
    "const = engine.connect()\n",
    "\n",
    "data_path = \"../data/\"\n",
    "csv_path = \"\\\\Users\\\\User\\\\iCloudDrive\\\\\"\n",
    "box_path = \"\\\\Users\\\\User\\\\Dropbox\\\\\"\n",
    "one_path = \"\\\\Users\\\\User\\\\OneDrive\\\\Documents\\\\Data\\\\\"\n",
    "\n",
    "pd.set_option('display.max_row', None)\n",
    "pd.set_option('display.max_column', None)\n",
    "\n",
    "today = date.today()\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process after last business day, yesterday must be last business day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today: 2022-12-18\n",
      "yesterday: 2022-12-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# specify the number of business days\n",
    "num_days = 1\n",
    "# convert the timedelta object to a BusinessDay object\n",
    "num_business_days = BDay(num_days)\n",
    "yesterday = today - num_business_days\n",
    "#yesterday = yesterday.date()\n",
    "print(f'today: {today}')\n",
    "print(f'yesterday: {yesterday}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'datetime.date' object has no attribute 'to_period'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11076/2143093488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# find the beginning of the week for the given yesterday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mweek_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myesterday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mweek_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myesterday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mweek_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweek_start\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mweek_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweek_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'datetime.date' object has no attribute 'to_period'"
     ]
    }
   ],
   "source": [
    "# find the beginning of the week for the given yesterday\n",
    "week_start = yesterday.to_period('W').start_time\n",
    "week_end = yesterday.to_period('W').end_time\n",
    "week_start = week_start.date()\n",
    "week_end = week_end.date()\n",
    "print(f'week start: {week_start}')\n",
    "print(f'week end: {week_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2022, 12, 12), datetime.date(2022, 12, 16))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yesterday = yesterday.date()\n",
    "week_start, yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s50_pct = 25\n",
    "s100_pct = 30\n",
    "s999_pct = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart and Run All Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'quarter price target_price upside buy hold sell yield max_price min_price pe pbv dly_vol beta'.split()\n",
    "colt = 'name price target_price upside buy hold sell market sector subsector dly_vol beta yield'.split()\n",
    "colu = 'price target_price upside buy hold sell mrkt yield'.split()\n",
    "\n",
    "format_dict = {\n",
    "    'latest_amt_y':'{:,}','previous_amt_y':'{:,}','inc_amt_y':'{:,}',   \n",
    "    'latest_amt_q':'{:,}','previous_amt_q':'{:,}','inc_amt_q':'{:,}',    \n",
    "    'q_amt_c':'{:,}','y_amt': '{:,}','inc_amt_py':'{:,}', \n",
    "    'q_amt_p': '{:,}','inc_amt_pq':'{:,}', \n",
    "    'inc_pct_y': '{:.2f}%','inc_pct_q': '{:.2f}%',\n",
    "    'inc_pct_py': '{:.2f}%','inc_pct_pq': '{:.2f}%',\n",
    "    'mean_pct': '{:.2f}%','std_pct': '{:.2f}%','upside': '{:.2f}%', \n",
    "    \n",
    "    'price':'{:.2f}','target_price':'{:.2f}','diff':'{:.2f}',\n",
    "    'eps_a':'{:.2f}','eps_b':'{:.2f}',                \n",
    "    'pe':'{:.2f}','pbv':'{:.2f}',\n",
    "    'yield':'{:.2f}%',\n",
    "    \n",
    "    'price':'{:.2f}','max_price':'{:.2f}','min_price':'{:.2f}',                \n",
    "    'pe':'{:.2f}','pbv':'{:.2f}',\n",
    "    'paid_up':'{:,.2f}','market_cap':'{:,.2f}',   \n",
    "    'daily_volume':'{:,.2f}','beta':'{:,.2f}', \n",
    "    'dly_vol':'{:,.2f}',    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM profits \n",
    "ORDER BY id DESC \n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "tmp = pd.read_sql(sql, conmy)\n",
    "tmp.style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = tmp['name'].values.tolist()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_p = \", \".join(map(lambda name: \"'%s'\" % name, names))\n",
    "in_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT * \n",
    "FROM consensus \n",
    "WHERE name IN (%s)\n",
    "'''\n",
    "sql = sql % in_p\n",
    "print(sql)\n",
    "\n",
    "tmp = pd.read_sql(sql, conmy)\n",
    "tmp.style.format(format_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT * FROM stocks \n",
    "WHERE name IN (%s)\n",
    "'''\n",
    "sql = sql % in_p\n",
    "print(sql)\n",
    "\n",
    "tmp = pd.read_sql(sql, conlite)\n",
    "tmp.style.format(format_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT * FROM tickers \n",
    "WHERE name IN (%s)\n",
    "'''\n",
    "sql = sql % in_p\n",
    "print(sql)\n",
    "\n",
    "tmp = pd.read_sql(sql, conmy)\n",
    "tmp.style.format(format_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT name, kind, year, quarter\n",
    "FROM profits\n",
    "ORDER BY name'''\n",
    "my_profits = pd.read_sql(sql, conmy)\n",
    "my_profits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT name, price, target_price, \n",
    "buy, hold, sell, yield, \n",
    "date(updated_at), ('%s'::date - date(updated_at)::date) AS days\n",
    "FROM consensus\n",
    "WHERE price > 0 AND target_price > 0\n",
    "\"\"\"\n",
    "sql = sql % (today)\n",
    "print(sql)\n",
    "#sql = sql % (today, today)\n",
    "#AND ('%s'::date - date(updated_at)::date) < 15\n",
    "consensus = pd.read_sql(sql, conpg)\n",
    "consensus.set_index('name', inplace=True)\n",
    "consensus['diff'] = consensus['target_price'] - consensus['price']\n",
    "consensus['upside'] = round(consensus['diff']/consensus['price']*100,2)\n",
    "consensus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consensus.loc['TSTH',['target','upside']] = [1.52,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_css = pd.merge(my_profits, consensus, on='name', how='inner')\n",
    "prf_css.sample(10).style.format(format_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_css.days.value_counts(normalize=True).to_frame().style.format('{:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = prf_css.loc[prf_css.days == 0]['name']\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_p = \", \".join(map(lambda name: \"'%s'\" % name, names))\n",
    "in_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlDel = '''\n",
    "DELETE FROM consensus \n",
    "WHERE name IN (%s)\n",
    "'''\n",
    "sqlDel = sqlDel % in_p\n",
    "print(sqlDel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rp = conpg.execute(sqlDel)\n",
    "#rp.rowcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there are deleted records, must rerun from select consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profits w/o consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(my_profits, consensus, on='name', how='outer',indicator=True)\n",
    "prf_wo_css = df_tmp['_merge'] == 'left_only'\n",
    "df_tmp[prf_wo_css]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df_tmp[prf_wo_css]['name']\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_p = \", \".join(map(lambda name: \"'%s'\" % name, names))\n",
    "in_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlDel = '''\n",
    "DELETE FROM profits\n",
    "WHERE name IN (%s)\n",
    "'''\n",
    "sqlDel = sqlDel % in_p\n",
    "print(sqlDel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = conmy.execute(sqlDel)\n",
    "rp.rowcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there are deleted records, must rerun from select profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start of Gain Percentage Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT name, max_price, min_price, pe, pbv, daily_volume AS dly_vol, beta, market\n",
    "FROM stocks\n",
    "'''\n",
    "my_stocks = pd.read_sql(sql, conmy)\n",
    "my_stocks.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\n",
    "   (my_stocks.market.str.contains('SET50')),\n",
    "   (my_stocks.market.str.contains('SET100')),\n",
    "   (my_stocks.market.str.contains('mai'))]\n",
    "values = ['SET50','SET100','mai']\n",
    "my_stocks[\"mrkt\"] = np.select(filters, values, default='SET999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stocks[\"mrkt\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_css_stk = pd.merge(prf_css, my_stocks, on='name', how='inner')\n",
    "prf_css_stk.set_index('name', inplace=True)\n",
    "prf_css_stk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set50 = prf_css_stk.mrkt.str.contains('SET50') & (prf_css_stk.upside >= s50_pct)\n",
    "flt_set50 = prf_css_stk[set50]\n",
    "flt_set50[cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_css_stk.loc\\\n",
    "    [prf_css_stk.mrkt.str.contains('SET50') & (prf_css_stk.upside < s50_pct)]\\\n",
    "    [cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set100 = prf_css_stk.mrkt.str.contains('SET100') & (prf_css_stk.upside >= s100_pct)\n",
    "flt_set100 = prf_css_stk[set100]\n",
    "flt_set100[cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_css_stk.loc\\\n",
    "    [prf_css_stk.mrkt.str.contains('SET100') & (prf_css_stk.upside < s100_pct)]\\\n",
    "    [cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set999 = prf_css_stk.mrkt.str.contains('SET999') & (prf_css_stk.upside >= s999_pct) \n",
    "flt_set999 = prf_css_stk[set999]\n",
    "flt_set999[cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prf_css_stk.loc\\\n",
    "    [(prf_css_stk.mrkt.str.contains('SET999')) & (prf_css_stk.upside < s999_pct)]\\\n",
    "    [cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mai = prf_css_stk.mrkt.str.contains('mai') & (prf_css_stk.upside >= s999_pct)\n",
    "flt_mai = prf_css_stk[mai]\n",
    "flt_mai[cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prf_css_stk.loc\\\n",
    "    [prf_css_stk.mrkt.str.contains('mai') & (prf_css_stk.upside < s999_pct)]\\\n",
    "    [cols].style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_all = pd.concat([flt_set50,flt_set100,flt_set999,flt_mai])\n",
    "flt_all.sort_values(['upside'],ascending=[False]).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_all[colu].sort_values(by='name',ascending=True).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'candidates to buy = ' + str(flt_all.shape[0]) + ' stocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT name, sector, subsector\n",
    "FROM tickers'''\n",
    "pg_tickers = pd.read_sql(sql, conpg)\n",
    "pg_tickers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(flt_all, pg_tickers, on='name', how='inner')\n",
    "final.reset_index()\n",
    "final[colt].sort_values(['name'],ascending=[True]).to_json(\"C:/ClearStep/dist/consensus.json\", orient=\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result to update to port_lite stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final[colt].sort_values(['name'],ascending=[True]).style.format(format_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching check with Buy table in MySql database to filter only records not yet in stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT name\n",
    "FROM buy\n",
    "WHERE active = 1\"\"\"\n",
    "buy_df = pd.read_sql(sql, const)\n",
    "buy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_buy = pd.merge(final, buy_df, on='name', how='outer', indicator=True)\n",
    "final_buy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_port = final_buy.loc[\n",
    "    final_buy['_merge'] == 'left_only']\n",
    "not_in_port[colt].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_port2 = not_in_port[colt].copy()\n",
    "not_in_port2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'consensus-ORD.csv'\n",
    "data_file = data_path + file_name\n",
    "output_file = csv_path + file_name\n",
    "box_file = box_path + file_name\n",
    "one_file = one_path + file_name\n",
    "\n",
    "not_in_port[colt].sort_values(['name'],ascending=[True]).to_csv(output_file, index=False)\n",
    "not_in_port[colt].sort_values(['name'],ascending=[True]).to_csv(data_file, index=False)\n",
    "not_in_port[colt].sort_values(['name'],ascending=[True]).to_csv(box_file, index=False)\n",
    "not_in_port[colt].sort_values(['name'],ascending=[True]).to_csv(one_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM stocks\"\"\"\n",
    "stocks = pd.read_sql(sql, conlite)\n",
    "stocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge4 = pd.merge(not_in_port2, stocks, on='name', how='outer', indicator=True)\n",
    "df_merge4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge4[df_merge4['_merge'] == 'left_only'].sort_values('name',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
